1) When you convert it to a 16-bit number, if you sign extend, you duplicate the most significant bit into the new larger bits. In this case, sign extending causes you to have many preceding 1s because d128 is b10000000.

2) 

#include <stdio.h>
int main()
{
    int a=12,b=255;
    printf("Output=%d",(a^b)+1;
    return 0;
}

The decimal output is 244, which is 0b11110100 and that in two's complement is equivalent to -12! Yay!

3) Perhaps it's normalized to 127 (b01111111) so that for exponents above that, your most significiant bit is always 1, and that can be used as a separator? And perhaps the reason that IEEE doesn't use twos complement or sign-bit is because they complicate things with the requirement of an extra bit or the limitation of the possible numbers you can use.

4) -13 comes out to be 11000001010100000000000000000000, which as an integer in decimal would be a whopping 3,243,245,568. Yikes.

5) 

#include <stdio.h>
int main()
{
    int a=12,b=255;
    printf("Output=%d",(a^b)+1;
    return 0;
}